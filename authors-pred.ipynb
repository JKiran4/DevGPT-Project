{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't run this every time! re-import the exported csv to save time.\n",
    "# commented out below to prevent accidental execution.\n",
    "\n",
    "# dirs = [(\"DevGPT/\" + d) for d in os.listdir(\"DevGPT\") if os.path.isdir(\"DevGPT/\" + d)] # modify this to limit snapshots\n",
    "\n",
    "# files = []\n",
    "# for dir in dirs:\n",
    "#     for f in os.listdir(dir):\n",
    "#         if f[-5:] == \".json\": files.append(dir + \"/\" + f)\n",
    "\n",
    "# print(files)\n",
    "\n",
    "# imports = []\n",
    "# for f in files:\n",
    "#     if f[-5:] == \".json\":  # this one pulls all files\n",
    "#         trydf = pd.read_json(f)\n",
    "#         trydf = pd.json_normalize(trydf[\"Sources\"])\n",
    "#         trydf[\"filepath\"] = f\n",
    "#         imports.append(trydf)\n",
    "\n",
    "# df = pd.concat(imports, ignore_index = True)\n",
    "# df.to_csv(\"df-export.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = pd.read_csv(\"df-export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Title   Body  Message  CommitMessage\n",
      "0   True  False    False          False\n",
      "     Title  Body  Message  CommitMessage\n",
      "138   True  True    False          False\n",
      "     Title  Body  Message  CommitMessage\n",
      "285   True  True    False          False\n",
      "     Title  Body  Message  CommitMessage\n",
      "520   True  True    False          False\n",
      "     Title   Body  Message  CommitMessage\n",
      "552  False  False     True          False\n",
      "     Title   Body  Message  CommitMessage\n",
      "731  False  False    False           True\n"
     ]
    }
   ],
   "source": [
    "dfa = dfi[[\"Type\", \"Author\", \"Title\", \"Body\", \"Message\", \"CommitMessage\", \"filepath\"]]\n",
    "\n",
    "# query statements, checking which columns have text to extract\n",
    "\n",
    "hn_q = \"filepath.str.contains('hn_sharings.json')\"     # Title\n",
    "pr_q = \"filepath.str.contains('pr_sharings.json')\"     # Title, Body\n",
    "is_q = \"filepath.str.contains('issue_sharings.json')\"     # Title, Body\n",
    "di_q = \"filepath.str.contains('discussion_sharings.json')\"    # Title, Body\n",
    "co_q = \"filepath.str.contains('commit_sharings.json')\"         # Message\n",
    "fi_q = \"filepath.str.contains('file_sharings.json')\"          # CommitMessage\n",
    "\n",
    "for query in [hn_q, pr_q, is_q, di_q, co_q, fi_q]:\n",
    "    print(~dfa.query(query)[[\"Title\", \"Body\", \"Message\", \"CommitMessage\"]].head(1).isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Local\\Temp\\ipykernel_27572\\3042202609.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfa[\"text\"] = dfa[[\"Title\", \"Body\", \"Message\", \"CommitMessage\"]].agg(lambda x: \"\".join(x.dropna().astype(str)), axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>cbowal</td>\n",
       "      <td>OpenAI shuts down its AI Classifier due to poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>warrenm</td>\n",
       "      <td>“Devil’s horsemen”: Why Mongol horse archers w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>ayhanfuat</td>\n",
       "      <td>The Fall of Stack Overflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>cdme</td>\n",
       "      <td>Death Metal English (2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>notRobot</td>\n",
       "      <td>Shopify employee breaks NDA to reveal firm rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>ingve</td>\n",
       "      <td>Integrating Zig and SwiftUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10662</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>scraptor</td>\n",
       "      <td>Lawyer cites fake cases invented by ChatGPT, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>admtal</td>\n",
       "      <td>Show HN: A chat bot you can ask anything about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>obiefernandez</td>\n",
       "      <td>ChatGPT conversations can be shared publicly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>arthurcolle</td>\n",
       "      <td>Show HN: Hacker News profile text can be used ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10666 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Type         Author  \\\n",
       "0      hacker news         cbowal   \n",
       "1      hacker news        warrenm   \n",
       "2      hacker news      ayhanfuat   \n",
       "3      hacker news           cdme   \n",
       "4      hacker news       notRobot   \n",
       "...            ...            ...   \n",
       "10661  hacker news          ingve   \n",
       "10662  hacker news       scraptor   \n",
       "10663  hacker news         admtal   \n",
       "10664  hacker news  obiefernandez   \n",
       "10665  hacker news    arthurcolle   \n",
       "\n",
       "                                                    text  \n",
       "0      OpenAI shuts down its AI Classifier due to poo...  \n",
       "1      “Devil’s horsemen”: Why Mongol horse archers w...  \n",
       "2                             The Fall of Stack Overflow  \n",
       "3                             Death Metal English (2013)  \n",
       "4      Shopify employee breaks NDA to reveal firm rep...  \n",
       "...                                                  ...  \n",
       "10661                        Integrating Zig and SwiftUI  \n",
       "10662  Lawyer cites fake cases invented by ChatGPT, j...  \n",
       "10663  Show HN: A chat bot you can ask anything about...  \n",
       "10664       ChatGPT conversations can be shared publicly  \n",
       "10665  Show HN: Hacker News profile text can be used ...  \n",
       "\n",
       "[10666 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine text columns\n",
    "\n",
    "dfa[\"text\"] = dfa[[\"Title\", \"Body\", \"Message\", \"CommitMessage\"]].agg(lambda x: \"\".join(x.dropna().astype(str)), axis = 1)\n",
    "dfa = dfa.drop([\"Title\", \"Body\", \"Message\", \"CommitMessage\", \"filepath\"], axis = 1)\n",
    "\n",
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Author</th>\n",
       "      <th>text_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>cbowal</td>\n",
       "      <td>[openai, shuts, down, its, ai, classifier, due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>warrenm</td>\n",
       "      <td>[devil, horsemen, why, mongol, horse, archers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>ayhanfuat</td>\n",
       "      <td>[the, fall, of, stack, overflow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>cdme</td>\n",
       "      <td>[death, metal, english]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>notRobot</td>\n",
       "      <td>[shopify, employee, breaks, nda, to, reveal, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>ingve</td>\n",
       "      <td>[integrating, zig, and, swiftui]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10662</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>scraptor</td>\n",
       "      <td>[lawyer, cites, fake, cases, invented, by, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>admtal</td>\n",
       "      <td>[show, hn, chat, bot, you, can, ask, anything,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>obiefernandez</td>\n",
       "      <td>[chatgpt, conversations, can, be, shared, publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>arthurcolle</td>\n",
       "      <td>[show, hn, hacker, news, profile, text, can, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10666 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Type         Author  \\\n",
       "0      hacker news         cbowal   \n",
       "1      hacker news        warrenm   \n",
       "2      hacker news      ayhanfuat   \n",
       "3      hacker news           cdme   \n",
       "4      hacker news       notRobot   \n",
       "...            ...            ...   \n",
       "10661  hacker news          ingve   \n",
       "10662  hacker news       scraptor   \n",
       "10663  hacker news         admtal   \n",
       "10664  hacker news  obiefernandez   \n",
       "10665  hacker news    arthurcolle   \n",
       "\n",
       "                                                 text_pp  \n",
       "0      [openai, shuts, down, its, ai, classifier, due...  \n",
       "1      [devil, horsemen, why, mongol, horse, archers,...  \n",
       "2                       [the, fall, of, stack, overflow]  \n",
       "3                                [death, metal, english]  \n",
       "4      [shopify, employee, breaks, nda, to, reveal, f...  \n",
       "...                                                  ...  \n",
       "10661                   [integrating, zig, and, swiftui]  \n",
       "10662  [lawyer, cites, fake, cases, invented, by, cha...  \n",
       "10663  [show, hn, chat, bot, you, can, ask, anything,...  \n",
       "10664  [chatgpt, conversations, can, be, shared, publ...  \n",
       "10665  [show, hn, hacker, news, profile, text, can, b...  \n",
       "\n",
       "[10666 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa[\"text_pp\"] = dfa[\"text\"].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "dfa = dfa.drop([\"text\"], axis = 1)\n",
    "\n",
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model - basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set classification accuracy: 88.61 %\n"
     ]
    }
   ],
   "source": [
    "# split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfa[\"text_pp\"], dfa[\"Author\"] , test_size = 0.2, random_state = 2)\n",
    "\n",
    "# apply word vector model on training data\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size = 100,\n",
    "                                   window = 5,\n",
    "                                   min_count = 2)\n",
    "\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "\n",
    "# create average sentence vectors to train on\n",
    "X_train_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                         if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_train])\n",
    "\n",
    "X_test_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                         if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_test])\n",
    "\n",
    "# define random forest model\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 2)\n",
    "\n",
    "# fit rf model to vectorized training data\n",
    "rf.fit(X_train_vect, y_train)\n",
    "\n",
    "# predict values on vectorized test data\n",
    "y_pred = rf.predict(X_test_vect)\n",
    "\n",
    "# report accuracy of test data predictions\n",
    "print(\"Test set classification accuracy: %.2f %%\" % (accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model - optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10666 rows in dataframe for authors with > 1 submissions -- 100.0 % of original.\n",
      "10557 rows in dataframe for authors with > 2 submissions -- 99.0 % of original.\n",
      "9558 rows in dataframe for authors with > 5 submissions -- 89.6 % of original.\n",
      "5624 rows in dataframe for authors with > 10 submissions -- 52.7 % of original.\n",
      "2483 rows in dataframe for authors with > 100 submissions -- 23.3 % of original.\n"
     ]
    }
   ],
   "source": [
    "# checking how many rows are removed for minimum comment thresholds\n",
    "for i in [1, 2, 5, 10, 100]:\n",
    "    count = len(dfa.groupby(\"Author\").filter(lambda x: len(x) >= i))\n",
    "    perc = count / len(dfa) * 100\n",
    "    print(\"%i rows in dataframe for authors with > %i submissions -- %.1f %% of original.\" %\n",
    "          (count, i, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Author</th>\n",
       "      <th>text_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>cbowal</td>\n",
       "      <td>[openai, shuts, down, its, ai, classifier, due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>warrenm</td>\n",
       "      <td>[devil, horsemen, why, mongol, horse, archers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>ayhanfuat</td>\n",
       "      <td>[the, fall, of, stack, overflow, hacker news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>cdme</td>\n",
       "      <td>[death, metal, english, hacker news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>notRobot</td>\n",
       "      <td>[shopify, employee, breaks, nda, to, reveal, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>ingve</td>\n",
       "      <td>[integrating, zig, and, swiftui, hacker news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10662</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>scraptor</td>\n",
       "      <td>[lawyer, cites, fake, cases, invented, by, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>admtal</td>\n",
       "      <td>[show, hn, chat, bot, you, can, ask, anything,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>obiefernandez</td>\n",
       "      <td>[chatgpt, conversations, can, be, shared, publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>hacker news</td>\n",
       "      <td>arthurcolle</td>\n",
       "      <td>[show, hn, hacker, news, profile, text, can, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9558 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Type         Author  \\\n",
       "0      hacker news         cbowal   \n",
       "1      hacker news        warrenm   \n",
       "2      hacker news      ayhanfuat   \n",
       "3      hacker news           cdme   \n",
       "4      hacker news       notRobot   \n",
       "...            ...            ...   \n",
       "10661  hacker news          ingve   \n",
       "10662  hacker news       scraptor   \n",
       "10663  hacker news         admtal   \n",
       "10664  hacker news  obiefernandez   \n",
       "10665  hacker news    arthurcolle   \n",
       "\n",
       "                                                 text_pp  \n",
       "0      [openai, shuts, down, its, ai, classifier, due...  \n",
       "1      [devil, horsemen, why, mongol, horse, archers,...  \n",
       "2          [the, fall, of, stack, overflow, hacker news]  \n",
       "3                   [death, metal, english, hacker news]  \n",
       "4      [shopify, employee, breaks, nda, to, reveal, f...  \n",
       "...                                                  ...  \n",
       "10661      [integrating, zig, and, swiftui, hacker news]  \n",
       "10662  [lawyer, cites, fake, cases, invented, by, cha...  \n",
       "10663  [show, hn, chat, bot, you, can, ask, anything,...  \n",
       "10664  [chatgpt, conversations, can, be, shared, publ...  \n",
       "10665  [show, hn, hacker, news, profile, text, can, b...  \n",
       "\n",
       "[9558 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove text from authors that have fewer than 5 comments\n",
    "dfb = dfa.groupby(\"Author\").filter(lambda x: len(x) >= 5)\n",
    "\n",
    "# include post type as a token \n",
    "dfb[\"text_pp\"] = dfb.apply(lambda row: row[\"text_pp\"] + [row[\"Type\"]], axis = 1)\n",
    "\n",
    "dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning w2v_model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 50 and window size 5:\n",
      "Test set classification accuracy: 0.915 , std dev: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 50 and window size 10:\n",
      "Test set classification accuracy: 0.915 , std dev: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 50 and window size 15:\n",
      "Test set classification accuracy: 0.915 , std dev: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 100 and window size 5:\n",
      "Test set classification accuracy: 0.916 , std dev: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 100 and window size 10:\n",
      "Test set classification accuracy: 0.914 , std dev: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 100 and window size 15:\n",
      "Test set classification accuracy: 0.916 , std dev: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 200 and window size 5:\n",
      "Test set classification accuracy: 0.915 , std dev: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 200 and window size 10:\n",
      "Test set classification accuracy: 0.914 , std dev: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model with vector size 200 and window size 15:\n",
      "Test set classification accuracy: 0.916 , std dev: 0.005\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfb[\"text_pp\"], dfb[\"Author\"] , test_size = 0.2, random_state = 2) \n",
    "# included Type column in text column this time for additional predictive power\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "\n",
    "for vec, win in [[50, 5], [50, 10], [50, 15],\n",
    "                 [100, 5], [100, 10], [100, 15],\n",
    "                 [200, 5], [200, 10], [200, 15]]:\n",
    "\n",
    "    scores = []\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "\n",
    "        X_tr = X_train.iloc[train_index]\n",
    "        X_te = X_train.iloc[test_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        y_te = y_train.iloc[test_index]\n",
    "\n",
    "        w2v_model = gensim.models.Word2Vec(X_tr,\n",
    "                                        vector_size = vec,\n",
    "                                        window = win,\n",
    "                                        min_count = 1)\n",
    "        # not too much extra to include all words: 12394 for count 1, 11685 for count 2 (default)\n",
    "\n",
    "        words = set(w2v_model.wv.index_to_key)\n",
    "\n",
    "        X_train_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                                if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                                for ls in X_tr])\n",
    "\n",
    "        X_test_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                                if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                                for ls in X_te])\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state = 2)\n",
    "\n",
    "        # fit rf model to vectorized training data\n",
    "        rf.fit(X_train_vect, y_tr)\n",
    "\n",
    "        # predict values on vectorized test data\n",
    "        y_pred = rf.predict(X_test_vect)\n",
    "\n",
    "        scores.append(accuracy_score(y_te, y_pred))\n",
    "    # report accuracy of test data predictions\n",
    "    print(\"For model with vector size %i and window size %i:\\nTest set classification accuracy: %.3f , std dev: %.3f\" % (vec, win, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set classification accuracy: 93.25 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfb[\"text_pp\"], dfb[\"Author\"] , test_size = 0.2, random_state = 2) \n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size = 50,\n",
    "                                   window = 10,\n",
    "                                   min_count = 1)\n",
    "\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "\n",
    "X_train_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                         if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_train])\n",
    "\n",
    "X_test_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                         if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_test])\n",
    "\n",
    "# define possible hyperparameters to tune\n",
    "rf_params = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "             \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "             \"n_estimators\": [10, 20, 50, 100],\n",
    "           \"max_depth\": range(1, 20)}\n",
    "\n",
    "rf_tuned = RandomizedSearchCV(RandomForestClassifier(), rf_params, n_iter = 10, cv = skf,\n",
    "                               random_state = 2, verbose = 1)\n",
    "\n",
    "rf_tuned.fit(X_train_vect, y_train)\n",
    "\n",
    "y_pred = rf_tuned.predict(X_test_vect)\n",
    "\n",
    "print(\"Test set classification accuracy: %.2f %%\" % (accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9135496308835285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 20,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 15,\n",
       " 'criterion': 'log_loss'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rf_tuned.best_score_)\n",
    "rf_tuned.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Test set classification accuracy: 98.31 %\n"
     ]
    }
   ],
   "source": [
    "# try to predict category?\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfa[\"text_pp\"], dfa[\"Type\"] , test_size = 0.2, random_state = 2) \n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size = 50,\n",
    "                                   window = 10,\n",
    "                                   min_count = 1)\n",
    "\n",
    "words = set(w2v_model.wv.index_to_key)\n",
    "\n",
    "X_train_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                         if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_train])\n",
    "\n",
    "X_test_vect = np.array([np.mean([w2v_model.wv[i] for i in ls if i in words], axis=0) \n",
    "                         if any(i in words for i in ls) else np.zeros(w2v_model.vector_size)\n",
    "                         for ls in X_test])\n",
    "\n",
    "# define possible hyperparameters to tune\n",
    "rf_params = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "             \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "             \"n_estimators\": [10, 20, 50, 100],\n",
    "           \"max_depth\": range(1, 20)}\n",
    "\n",
    "rf_tuned = RandomizedSearchCV(RandomForestClassifier(), rf_params, n_iter = 10, cv = skf,\n",
    "                               random_state = 2, verbose = 1)\n",
    "\n",
    "rf_tuned.fit(X_train_vect, y_train)\n",
    "\n",
    "y_pred = rf_tuned.predict(X_test_vect)\n",
    "\n",
    "print(\"Test set classification accuracy: %.2f %%\" % (accuracy_score(y_test, y_pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
